{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4def23",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73e27da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten,\n",
    "    SeparableConv2D, GlobalMaxPooling2D, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd7910a",
   "metadata": {},
   "source": [
    "## 2. Configure Dataset Paths\n",
    "\n",
    "Update these paths according to your local directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad5d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths - update these to your local paths\n",
    "BASE_DIR = os.path.dirname(os.path.abspath('__file__'))  # Current directory\n",
    "\n",
    "train_dir = os.path.join(BASE_DIR, 'train')\n",
    "val_dir = os.path.join(BASE_DIR, 'val')\n",
    "test_dir = os.path.join(BASE_DIR, 'test')\n",
    "\n",
    "print(f\"Train directory: {train_dir}\")\n",
    "print(f\"Validation directory: {val_dir}\")\n",
    "print(f\"Test directory: {test_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe83bbd",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Dataset\n",
    "\n",
    "We load chest X-ray images in grayscale and convert them to RGB for compatibility with VGG16 pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1861bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_size = (224, 224)\n",
    "\n",
    "# Create raw datasets\n",
    "train_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "val_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "test_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "# Get class names before transformation\n",
    "class_names = train_raw.class_names\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Total Classes: {len(class_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caddc1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert grayscale to RGB (required for VGG16 weight compatibility)\n",
    "def convert_gray_to_rgb(image, label):\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Apply mapping + prefetch for performance\n",
    "train_ds = train_raw.map(convert_gray_to_rgb).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_raw.map(convert_gray_to_rgb).prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_raw.map(convert_gray_to_rgb).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data shape\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(f\"Image batch shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ebea3e",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3063f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype('uint8'), cmap='gray')\n",
    "        label_idx = labels[i].numpy()\n",
    "        plt.title(class_names[label_idx])\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.suptitle('Sample Training Images', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36493931",
   "metadata": {},
   "source": [
    "## 5. Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfcebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images per class\n",
    "class_counts = {}\n",
    "\n",
    "for class_name in os.listdir(train_dir):\n",
    "    folder_path = os.path.join(train_dir, class_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        class_counts[class_name] = len(os.listdir(folder_path))\n",
    "\n",
    "print(\"Image count per class (Training Set):\")\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(class_counts.keys(), class_counts.values(), color=['green', 'red'])\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Training Set Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d45f7",
   "metadata": {},
   "source": [
    "## 6. Data Augmentation\n",
    "\n",
    "To handle class imbalance and improve generalization, we apply data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e076df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation layer\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.3),\n",
    "    layers.RandomZoom(0.2),\n",
    "])\n",
    "\n",
    "# Apply augmentation and optimize pipeline\n",
    "train_dataset = train_ds.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y),\n",
    "    num_parallel_calls=AUTOTUNE\n",
    ")\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ad6f2",
   "metadata": {},
   "source": [
    "## 7. Compute Class Weights\n",
    "\n",
    "Class weights help the model handle imbalanced data by penalizing mistakes on the minority class more heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f593fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights for imbalanced data\n",
    "class_names_list = ['NORMAL', 'PNEUMONIA']\n",
    "image_counts = [class_counts.get('NORMAL', 1341), class_counts.get('PNEUMONIA', 3875)]\n",
    "\n",
    "y = np.repeat(np.arange(len(class_names_list)), image_counts)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(f\"Computed Class Weights: {class_weights_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c887d7",
   "metadata": {},
   "source": [
    "## 8. Build CNN Model Architecture\n",
    "\n",
    "Our model uses:\n",
    "- **Conv2D layers** (first 2 blocks): Standard convolutions initialized with VGG16 weights\n",
    "- **SeparableConv2D layers**: Efficient depthwise separable convolutions\n",
    "- **BatchNormalization**: For training stability\n",
    "- **Dropout**: For regularization (0.7 and 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fa77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    Build a custom CNN for pneumonia detection.\n",
    "    \n",
    "    Architecture:\n",
    "    - 2 Conv2D blocks (compatible with VGG16 pretrained weights)\n",
    "    - 2 SeparableConv2D blocks with BatchNormalization\n",
    "    - Dense layers with Dropout for classification\n",
    "    \n",
    "    Returns:\n",
    "        keras.Model: Compiled model ready for training\n",
    "    \"\"\"\n",
    "    input_img = Input(shape=(224, 224, 3), name='ImageInput')\n",
    "    \n",
    "    # Block 1 - Conv2D (VGG16 weights compatible)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2, 2), name='pool1')(x)\n",
    "    \n",
    "    # Block 2 - SeparableConv2D\n",
    "    x = SeparableConv2D(128, (3, 3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3, 3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2, 2), name='pool2')(x)\n",
    "    \n",
    "    # Block 3 - SeparableConv2D with BatchNorm\n",
    "    x = SeparableConv2D(256, (3, 3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2, 2), name='pool3')(x)\n",
    "    \n",
    "    # Block 4 - SeparableConv2D with BatchNorm\n",
    "    x = SeparableConv2D(512, (3, 3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3, 3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3, 3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2, 2), name='pool4')(x)\n",
    "    \n",
    "    # Classification Head\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.7, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(1, activation='sigmoid', name='fc3')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e4c72",
   "metadata": {},
   "source": [
    "## 9. Transfer Learning: Load VGG16 Pretrained Weights\n",
    "\n",
    "We load VGG16 pretrained weights for the first two convolutional layers to benefit from features learned on ImageNet.\n",
    "\n",
    "> **Note**: Download VGG16 weights file (`vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5`) before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05824960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 pretrained weights for early layers\n",
    "VGG16_WEIGHTS_PATH = 'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "if os.path.exists(VGG16_WEIGHTS_PATH):\n",
    "    with h5py.File(VGG16_WEIGHTS_PATH, 'r') as f:\n",
    "        layer_map = {\n",
    "            'Conv1_1': 'block1_conv1',\n",
    "            'Conv1_2': 'block1_conv2',\n",
    "        }\n",
    "\n",
    "        for your_layer_name, vgg_layer_name in layer_map.items():\n",
    "            target_layer = model.get_layer(your_layer_name)\n",
    "\n",
    "            if len(target_layer.weights) == 2:\n",
    "                w = f[vgg_layer_name][f\"{vgg_layer_name}_W_1:0\"][()]\n",
    "                b = f[vgg_layer_name][f\"{vgg_layer_name}_b_1:0\"][()]\n",
    "                target_layer.set_weights([w, b])\n",
    "                print(f\"âœ… Loaded VGG16 weights for {your_layer_name}\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ Skipping {your_layer_name} (incompatible layer type)\")\n",
    "    print(\"\\nâœ… VGG16 transfer learning weights loaded successfully!\")\n",
    "else:\n",
    "    print(f\"âš ï¸ VGG16 weights file not found at: {VGG16_WEIGHTS_PATH}\")\n",
    "    print(\"Proceeding with random initialization for Conv layers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f2f32",
   "metadata": {},
   "source": [
    "## 10. Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81724c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model_weights.weights.h5',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss'\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"âœ… Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e95868f",
   "metadata": {},
   "source": [
    "## 11. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a796a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "EPOCHS = 20\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    class_weight={0: 1.0, 1: 0.4}  # Adjusted class weights\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e025d57",
   "metadata": {},
   "source": [
    "## 12. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54172da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0].plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "axes[0].set_title('Model Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss plot\n",
    "axes[1].plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "axes[1].set_title('Model Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90477c5b",
   "metadata": {},
   "source": [
    "## 13. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ea1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"\\nâœ… Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"ðŸ§ª Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e80009",
   "metadata": {},
   "source": [
    "## 14. Confusion Matrix & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    y_true.extend(labels.numpy())\n",
    "    preds = model.predict(images, verbose=0)\n",
    "    y_pred.extend((preds > 0.5).astype(\"int\").flatten())\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Normal', 'Pneumonia'],\n",
    "            yticklabels=['Normal', 'Pneumonia'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Normal', 'Pneumonia']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dce318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision and recall\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"\\nðŸ“Š Precision: {precision:.4f}\")\n",
    "print(f\"ðŸ“Š Recall (Sensitivity): {recall:.4f}\")\n",
    "print(f\"ðŸ“Š F1-Score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a363a230",
   "metadata": {},
   "source": [
    "## 15. Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5964a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in Keras format (required for Grad-CAM)\n",
    "model.save('resume_model.keras')\n",
    "print(\"âœ… Model saved as 'resume_model.keras'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f10353",
   "metadata": {},
   "source": [
    "## 16. Convert to TensorFlow Lite (for Deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f24ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TFLite for efficient deployment\n",
    "print(\"Converting to TFLite...\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"âœ… TFLite model saved as 'model.tflite'\")\n",
    "print(f\"ðŸ“¦ TFLite model size: {os.path.getsize('model.tflite') / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3622448",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrates the complete training pipeline for a pneumonia detection model:\n",
    "\n",
    "1. **Data Loading**: Loaded chest X-ray images from train/val/test directories\n",
    "2. **Preprocessing**: Converted grayscale to RGB, applied data augmentation\n",
    "3. **Model Architecture**: Custom CNN with VGG16 transfer learning\n",
    "4. **Training**: Used Adam optimizer, early stopping, and class weights\n",
    "5. **Evaluation**: Assessed performance using accuracy, precision, recall, and F1-score\n",
    "6. **Export**: Saved model in Keras format (for Grad-CAM) and TFLite (for deployment)\n",
    "\n",
    "### Output Files\n",
    "- `resume_model.keras` - Full Keras model (for Grad-CAM explainability)\n",
    "- `model.tflite` - Optimized TFLite model (for fast inference)\n",
    "\n",
    "### Next Steps\n",
    "- Run the Streamlit app (`chest_xray/app.py`) to test the model with Grad-CAM visualization\n",
    "- Fine-tune hyperparameters for better performance\n",
    "- Experiment with different augmentation strategies"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
