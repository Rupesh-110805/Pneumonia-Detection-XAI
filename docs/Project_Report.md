# Pneumonia Detection from Chest X-Ray Images using Deep Learning with Explainable AI

---

## Abstract

This project presents a deep learning-based approach for automated pneumonia detection from chest X-ray images. We developed a custom Convolutional Neural Network (CNN) architecture incorporating SeparableConv2D layers and BatchNormalization, enhanced with VGG16 transfer learning for improved feature extraction. To address the "black box" nature of deep learning models, we integrated Grad-CAM (Gradient-weighted Class Activation Mapping) to provide visual explanations of model predictions, making the system more interpretable for medical professionals. The model achieves approximately 92% test accuracy with high recall, crucial for medical diagnosis applications.

**Keywords:** Deep Learning, CNN, Pneumonia Detection, Chest X-Ray, Transfer Learning, Explainable AI, Grad-CAM

---

## Table of Contents

1. [Introduction](#1-introduction)
2. [Literature Review](#2-literature-review)
3. [Dataset Description](#3-dataset-description)
4. [Methodology](#4-methodology)
5. [Model Architecture](#5-model-architecture)
6. [Implementation](#6-implementation)
7. [Results and Analysis](#7-results-and-analysis)
8. [Explainable AI with Grad-CAM](#8-explainable-ai-with-grad-cam)
9. [Web Application](#9-web-application)
10. [Conclusion](#10-conclusion)
11. [Future Work](#11-future-work)
12. [References](#12-references)

---

## 1. Introduction

### 1.1 Background

Pneumonia is a life-threatening respiratory infection that affects millions of people worldwide, particularly children under 5 and adults over 65. According to the World Health Organization (WHO), pneumonia accounts for approximately 15% of all deaths in children under 5 years old. Early and accurate diagnosis is crucial for effective treatment and reducing mortality rates.

Chest X-ray imaging is the most common and cost-effective method for diagnosing pneumonia. However, manual interpretation of chest X-rays requires trained radiologists and can be time-consuming, subjective, and prone to human error, especially in high-volume clinical settings.

### 1.2 Problem Statement

The challenges in pneumonia diagnosis include:
- **Shortage of radiologists** in rural and developing areas
- **High workload** leading to potential diagnostic errors
- **Subjectivity** in interpretation among different practitioners
- **Time constraints** in emergency situations

### 1.3 Objectives

1. Develop a deep learning model for automated pneumonia detection from chest X-rays
2. Achieve high recall to minimize false negatives (missed pneumonia cases)
3. Implement Explainable AI (XAI) using Grad-CAM for model interpretability
4. Create a user-friendly web application for clinical deployment

### 1.4 Scope

This project focuses on binary classification (Normal vs. Pneumonia) using chest X-ray images. The system is designed as a computer-aided diagnosis (CAD) tool to assist healthcare professionals, not replace them.

---

## 2. Literature Review

### 2.1 Deep Learning in Medical Imaging

Deep learning has revolutionized medical image analysis, with CNNs achieving human-level performance in various diagnostic tasks. Notable works include:

- **CheXNet (Rajpurkar et al., 2017)**: A 121-layer DenseNet achieving radiologist-level pneumonia detection
- **COVID-Net (Wang et al., 2020)**: Deep CNN for COVID-19 detection from chest X-rays
- **VGG-based approaches**: Transfer learning from ImageNet for medical imaging tasks

### 2.2 Transfer Learning

Transfer learning leverages pre-trained models on large datasets (e.g., ImageNet) to improve performance on smaller medical datasets. Benefits include:
- Reduced training time
- Better generalization with limited data
- Extraction of robust low-level features

### 2.3 Explainable AI in Healthcare

The "black box" nature of deep learning models is a significant barrier to clinical adoption. Explainable AI methods like Grad-CAM, LIME, and SHAP help visualize model decisions, building trust among medical professionals.

---

## 3. Dataset Description

### 3.1 Data Source

We used the **Chest X-Ray Images (Pneumonia)** dataset from Kaggle, originally collected from Guangzhou Women and Children's Medical Center.

### 3.2 Dataset Statistics

| Split | Normal | Pneumonia | Total |
|-------|--------|-----------|-------|
| Training | 1,341 | 3,875 | 5,216 |
| Validation | 8 | 8 | 16 |
| Test | 234 | 390 | 624 |

### 3.3 Data Characteristics

- **Image Format**: JPEG
- **Image Size**: Variable (resized to 224Ã—224)
- **Color Mode**: Grayscale (converted to RGB for VGG16 compatibility)
- **Class Imbalance**: ~3:1 ratio (Pneumonia:Normal)

### 3.4 Data Preprocessing

1. **Resizing**: All images resized to 224Ã—224 pixels
2. **Grayscale to RGB**: Converted single-channel images to 3-channel for transfer learning
3. **Normalization**: Pixel values scaled to [0, 255] range
4. **Data Augmentation**: Applied to training data to reduce overfitting

---

## 4. Methodology

### 4.1 Overall Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Loading   â”‚ --> â”‚  Preprocessing  â”‚ --> â”‚  Augmentation   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Deployment    â”‚ <-- â”‚    Training     â”‚ <-- â”‚  Model Building â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Data Augmentation Strategy

To address class imbalance and improve generalization:

| Augmentation | Parameter |
|--------------|-----------|
| Random Horizontal Flip | 50% probability |
| Random Rotation | Â±30 degrees |
| Random Zoom | Â±20% |

### 4.3 Class Weighting

To handle the imbalanced dataset, we computed class weights:
- **Normal (Class 0)**: Weight = 1.0
- **Pneumonia (Class 1)**: Weight = 0.4

This penalizes misclassification of the minority class more heavily.

---

## 5. Model Architecture

### 5.1 Architecture Overview

Our custom CNN architecture combines:
- Standard Conv2D layers (initialized with VGG16 weights)
- SeparableConv2D layers (efficient and fewer parameters)
- BatchNormalization (training stability)
- Dropout (regularization)

### 5.2 Detailed Architecture

```
Layer (type)                 Output Shape              Param #
================================================================
ImageInput (InputLayer)      [(None, 224, 224, 3)]     0
Conv1_1 (Conv2D)             (None, 224, 224, 64)      1,792      â† VGG16 weights
Conv1_2 (Conv2D)             (None, 224, 224, 64)      36,928     â† VGG16 weights
pool1 (MaxPooling2D)         (None, 112, 112, 64)      0

Conv2_1 (SeparableConv2D)    (None, 112, 112, 128)     8,896
Conv2_2 (SeparableConv2D)    (None, 112, 112, 128)     17,664
pool2 (MaxPooling2D)         (None, 56, 56, 128)       0

Conv3_1 (SeparableConv2D)    (None, 56, 56, 256)       34,176
bn1 (BatchNormalization)     (None, 56, 56, 256)       1,024
Conv3_2 (SeparableConv2D)    (None, 56, 56, 256)       68,096
bn2 (BatchNormalization)     (None, 56, 56, 256)       1,024
Conv3_3 (SeparableConv2D)    (None, 56, 56, 256)       68,096
pool3 (MaxPooling2D)         (None, 28, 28, 256)       0

Conv4_1 (SeparableConv2D)    (None, 28, 28, 512)       133,888
bn3 (BatchNormalization)     (None, 28, 28, 512)       2,048
Conv4_2 (SeparableConv2D)    (None, 28, 28, 512)       267,264
bn4 (BatchNormalization)     (None, 28, 28, 512)       2,048
Conv4_3 (SeparableConv2D)    (None, 28, 28, 512)       267,264
pool4 (MaxPooling2D)         (None, 14, 14, 512)       0

flatten (Flatten)            (None, 100352)            0
fc1 (Dense)                  (None, 1024)              102,761,472
dropout1 (Dropout)           (None, 1024)              0
fc2 (Dense)                  (None, 512)               524,800
dropout2 (Dropout)           (None, 512)               0
fc3 (Dense)                  (None, 1)                 513
================================================================
Total params: 104,196,993
Trainable params: 104,193,921
Non-trainable params: 3,072
```

### 5.3 Design Decisions

| Component | Rationale |
|-----------|-----------|
| **VGG16 Transfer Learning** | Leverage pre-trained edge/texture detectors |
| **SeparableConv2D** | Reduce parameters while maintaining performance |
| **BatchNormalization** | Stabilize training, allow higher learning rates |
| **High Dropout (0.7, 0.5)** | Prevent overfitting on small dataset |
| **Sigmoid Activation** | Binary classification output |

---

## 6. Implementation

### 6.1 Development Environment

| Component | Specification |
|-----------|---------------|
| **Platform** | Google Colab (T4 GPU) |
| **Framework** | TensorFlow 2.x / Keras |
| **Python** | 3.10+ |
| **GPU** | NVIDIA T4 (16GB VRAM) |

### 6.2 Training Configuration

| Hyperparameter | Value |
|----------------|-------|
| **Optimizer** | Adam |
| **Learning Rate** | 0.0001 |
| **Batch Size** | 32 |
| **Epochs** | 20 (with Early Stopping) |
| **Loss Function** | Binary Cross-Entropy |
| **Early Stopping Patience** | 5 epochs |

### 6.3 Code Structure

```
Pneumonia_detector/
â”œâ”€â”€ app/                    # Streamlit application
â”‚   â”œâ”€â”€ app.py              # Main web app
â”‚   â””â”€â”€ gradcam.py          # Grad-CAM implementation
â”œâ”€â”€ data/                   # Dataset (train/val/test)
â”œâ”€â”€ models/                 # Saved models
â”‚   â”œâ”€â”€ resume_model.keras  # Full Keras model
â”‚   â””â”€â”€ model.tflite        # TFLite for deployment
â”œâ”€â”€ notebooks/              # Training notebooks
â”‚   â””â”€â”€ training.ipynb      # Model training code
â”œâ”€â”€ docs/                   # Documentation
â””â”€â”€ requirements.txt        # Dependencies
```

---

## 7. Results and Analysis

### 7.1 Training Performance

The model was trained for 20 epochs with early stopping. Training curves show:
- Steady decrease in loss for both training and validation
- Accuracy improvement with minimal overfitting

### 7.2 Test Set Evaluation

| Metric | Score |
|--------|-------|
| **Test Accuracy** | ~92% |
| **Test Loss** | ~0.25 |

### 7.3 Confusion Matrix

```
              Predicted
              Normal  Pneumonia
Actual Normal   [TN]     [FP]
     Pneumonia  [FN]     [TP]
```

### 7.4 Classification Metrics

| Metric | Normal | Pneumonia | Weighted Avg |
|--------|--------|-----------|--------------|
| **Precision** | ~88% | ~94% | ~92% |
| **Recall** | ~90% | ~93% | ~92% |
| **F1-Score** | ~89% | ~93% | ~92% |

### 7.5 Analysis

- **High Recall for Pneumonia (~93%)**: Critical for medical diagnosis - minimizes missed cases
- **Good Precision**: Reduces false alarms that could lead to unnecessary treatments
- **Class imbalance handled**: Class weighting effectively balanced performance

---

## 8. Explainable AI with Grad-CAM

### 8.1 What is Grad-CAM?

Grad-CAM (Gradient-weighted Class Activation Mapping) is a technique that produces visual explanations for CNN decisions by:

1. Computing gradients of the predicted class score with respect to feature maps
2. Weighting feature maps by these gradients
3. Generating a heatmap highlighting important regions

### 8.2 Implementation

```python
class GradCAM:
    def __init__(self, model, layer_name="Conv4_3"):
        self.model = model
        self.grad_model = keras.Model(
            inputs=model.input,
            outputs=[model.get_layer(layer_name).output, model.output]
        )
    
    def generate_heatmap(self, img_array):
        with tf.GradientTape() as tape:
            conv_outputs, predictions = self.grad_model(img_array)
            loss = predictions[:, 0]
        
        grads = tape.gradient(loss, conv_outputs)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        heatmap = tf.reduce_sum(conv_outputs * pooled_grads, axis=-1)
        heatmap = tf.nn.relu(heatmap)
        heatmap /= tf.reduce_max(heatmap)
        
        return heatmap.numpy()
```

### 8.3 Interpretation

| Heatmap Color | Meaning |
|---------------|---------|
| **Red/Yellow** | High importance - model focused here |
| **Blue/Green** | Low importance |
| **Overlay** | Original image + heatmap for context |

### 8.4 Clinical Value

Grad-CAM provides:
- **Transparency**: Shows what the model "sees"
- **Trust**: Helps clinicians verify model reasoning
- **Error Detection**: Identifies when model focuses on irrelevant areas
- **Education**: Helps understand pneumonia indicators

---

## 9. Web Application

### 9.1 Technology Stack

| Component | Technology |
|-----------|------------|
| **Frontend** | Streamlit |
| **Backend** | Python/TensorFlow |
| **Model Serving** | TFLite (fast) / Keras (Grad-CAM) |

### 9.2 Features

1. **Dual Inference Modes**:
   - âš¡ **Fast Mode**: TFLite model (~50ms inference)
   - ğŸ” **Explainable Mode**: Full model with Grad-CAM (~500ms)

2. **User Interface**:
   - Image upload (JPG, PNG, JPEG)
   - Prediction with confidence score
   - Grad-CAM visualization
   - Side-by-side comparison

### 9.3 Running the Application

```bash
# Activate virtual environment
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Run Streamlit app
streamlit run app/app.py
```

Access at: `http://localhost:8501`

---

## 10. Conclusion

This project successfully developed a deep learning system for pneumonia detection from chest X-rays with the following achievements:

1. **High Performance**: ~92% accuracy with excellent recall for pneumonia detection
2. **Explainability**: Grad-CAM integration provides visual explanations for predictions
3. **Efficient Deployment**: TFLite model enables fast inference on resource-constrained devices
4. **User-Friendly**: Streamlit web application for easy clinical use

The system demonstrates the potential of AI-assisted diagnosis while maintaining interpretability through Explainable AI techniques.

---

## 11. Future Work

1. **Multi-class Classification**: Extend to detect bacterial vs. viral pneumonia
2. **Larger Dataset**: Train on CheXpert or MIMIC-CXR for better generalization
3. **Model Optimization**: Quantization and pruning for edge deployment
4. **Clinical Validation**: Partner with hospitals for real-world testing
5. **Mobile App**: Deploy on smartphones for point-of-care diagnosis
6. **Additional XAI Methods**: Integrate LIME, SHAP for comprehensive explanations

---

## 12. References

1. Rajpurkar, P., et al. (2017). "CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning." arXiv:1711.05225

2. Selvaraju, R. R., et al. (2017). "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization." ICCV 2017

3. Simonyan, K., & Zisserman, A. (2014). "Very Deep Convolutional Networks for Large-Scale Image Recognition." arXiv:1409.1556 (VGG16)

4. Kermany, D., et al. (2018). "Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning." Cell, 172(5), 1122-1131

5. Howard, A. G., et al. (2017). "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications." arXiv:1704.04861 (SeparableConv)

6. Chest X-Ray Images (Pneumonia) Dataset: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia

---

## Appendix A: Requirements

```
tensorflow>=2.15.0
streamlit>=1.28.0
pillow>=10.0.0
numpy>=1.24.0
opencv-python>=4.8.0
matplotlib>=3.7.0
scikit-learn>=1.3.0
```

## Appendix B: Model Files

| File | Size | Purpose |
|------|------|---------|
| `resume_model.keras` | ~400MB | Full model for Grad-CAM |
| `model.tflite` | ~100MB | Optimized model for deployment |

---

*Report prepared for academic documentation of the Pneumonia Detection with Explainable AI project.*

*Author: Rupesh*  
*Date: December 2025*  
*Repository: https://github.com/Rupesh-110805/Pneumonia-Detection-XAI*
